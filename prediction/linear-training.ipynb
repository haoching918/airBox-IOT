{"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"id":"8LFPhfFSh56z","colab":{"base_uri":"https://localhost:8080/","height":278},"outputId":"4cab1abb-52ea-486e-9ac0-e31b3015eb34","execution":{"iopub.status.busy":"2023-06-07T15:17:14.548215Z","iopub.execute_input":"2023-06-07T15:17:14.548613Z","iopub.status.idle":"2023-06-07T15:17:14.555009Z","shell.execute_reply.started":"2023-06-07T15:17:14.548580Z","shell.execute_reply":"2023-06-07T15:17:14.553713Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/training-data/data.csv')\ndf = df.sort_values(by=['deviceId', 'timestamp'])\n","metadata":{"id":"mnKlVM6niS4h","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"55e312f4-bfb2-4dfd-c6fb-2c3fc7767464","execution":{"iopub.status.busy":"2023-06-07T15:17:14.557427Z","iopub.execute_input":"2023-06-07T15:17:14.558147Z","iopub.status.idle":"2023-06-07T15:17:14.948997Z","shell.execute_reply.started":"2023-06-07T15:17:14.558092Z","shell.execute_reply":"2023-06-07T15:17:14.948024Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# imputation\nfor column in df.columns[5:]:\n  if np.any(df[column] <= 0):  # Check if column contains negative values\n      column_mean = df[column].mean()  # Calculate column mean\n      df[column] = np.where(df[column] <= 0, column_mean, df[column])  # Replace negative values with mean\n","metadata":{"id":"XK8d5St4CJbE","execution":{"iopub.status.busy":"2023-06-07T15:17:14.950628Z","iopub.execute_input":"2023-06-07T15:17:14.951002Z","iopub.status.idle":"2023-06-07T15:17:14.973184Z","shell.execute_reply.started":"2023-06-07T15:17:14.950966Z","shell.execute_reply":"2023-06-07T15:17:14.972163Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# normalize\nscaler = MinMaxScaler()\ntarget_columns = ['temp','WDSD','pm2.5']  # Select only numeric columns\nfor column in target_columns:\n    df[column] = scaler.fit_transform(df[column].values.reshape(-1, 1))","metadata":{"id":"Zf2o0q-dodoV","execution":{"iopub.status.busy":"2023-06-07T15:17:14.976359Z","iopub.execute_input":"2023-06-07T15:17:14.976745Z","iopub.status.idle":"2023-06-07T15:17:14.990187Z","shell.execute_reply.started":"2023-06-07T15:17:14.976712Z","shell.execute_reply":"2023-06-07T15:17:14.989225Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class PM25Dataset(Dataset):\n    def __init__(self, data):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        return self.data[idx]","metadata":{"id":"kd-yRG3riclV","execution":{"iopub.status.busy":"2023-06-07T15:17:14.991783Z","iopub.execute_input":"2023-06-07T15:17:14.992169Z","iopub.status.idle":"2023-06-07T15:17:15.000426Z","shell.execute_reply.started":"2023-06-07T15:17:14.992136Z","shell.execute_reply":"2023-06-07T15:17:14.999406Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# creating training and testing data\ndatasets = []\nfor device_id, group in df.groupby('deviceId'):\n    group = group.drop(columns=['deviceId', 'timestamp', 'Unnamed: 0'])  # Drop non-feature columns\n    group_values = group.values # 24 * 5\n    dataset = PM25Dataset(group_values)\n    datasets.append(dataset)\n\ndataset = ConcatDataset(datasets)\ntrain_size = int(0.8 * len(dataset))  # Let's use 80% of the data for training\n\ntest_size = len(dataset) - train_size\ntrain_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=1000, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)","metadata":{"id":"SMsYc9dWie5k","execution":{"iopub.status.busy":"2023-06-07T15:17:15.002883Z","iopub.execute_input":"2023-06-07T15:17:15.003342Z","iopub.status.idle":"2023-06-07T15:17:15.683813Z","shell.execute_reply.started":"2023-06-07T15:17:15.003308Z","shell.execute_reply":"2023-06-07T15:17:15.682841Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# init device to store data\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"fYcFtdwPxNxj","execution":{"iopub.status.busy":"2023-06-07T15:17:15.685479Z","iopub.execute_input":"2023-06-07T15:17:15.685866Z","iopub.status.idle":"2023-06-07T15:17:15.691135Z","shell.execute_reply.started":"2023-06-07T15:17:15.685832Z","shell.execute_reply":"2023-06-07T15:17:15.690008Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Define the Linear Regression model\nclass LinearRegression(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LinearRegression, self).__init__()\n        self.fc = nn.Linear(input_size, output_size)\n    \n    def forward(self, x):\n        out = self.fc(x)\n        return out\n\n# Hyperparameters\ninput_size = 5 # PM2.5, temperature, wind speed, longitude, latitude\nhidden_size = 30\nnum_layers = 8\noutput_size = 1 # Next PM2.5\nnum_epochs = 250\nlearning_rate = 0.0001\n\n\n# Initialize the model, loss function, and optimizer\nmodel = LinearRegression(input_size, output_size)\nmodel = model.to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"id":"TrAGqm2TimJC","execution":{"iopub.status.busy":"2023-06-07T15:17:15.692814Z","iopub.execute_input":"2023-06-07T15:17:15.693216Z","iopub.status.idle":"2023-06-07T15:17:15.703983Z","shell.execute_reply.started":"2023-06-07T15:17:15.693181Z","shell.execute_reply":"2023-06-07T15:17:15.702935Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"# Training loop\nnum_epochs = 100\nfor epoch in range(num_epochs):\n    for inputs in train_loader:\n        # Forward pass\n        inputs = inputs.float()\n        inputs=inputs.to(device)\n        outputs = model(inputs[:, :-1])  # Exclude the last column (PM2.5) from inputs\n        \n        # Compute loss\n        targets = inputs[:, -1:]  # Last column contains the PM2.5 values\n        targets = targets.to(device)\n        loss = criterion(outputs, targets)\n        \n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    if (epoch+1) % 10 == 0:\n        # Print training loss for each epoch\n        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')","metadata":{"id":"9cSEXiM5iq7V","execution":{"iopub.status.busy":"2023-06-07T15:17:15.707515Z","iopub.execute_input":"2023-06-07T15:17:15.707922Z","iopub.status.idle":"2023-06-07T15:19:32.061702Z","shell.execute_reply.started":"2023-06-07T15:17:15.707887Z","shell.execute_reply":"2023-06-07T15:19:32.060756Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Epoch 10/100, Loss: 106.46006774902344\nEpoch 20/100, Loss: 118.3214340209961\nEpoch 30/100, Loss: 107.87921905517578\nEpoch 40/100, Loss: 118.25617218017578\nEpoch 50/100, Loss: 109.83740997314453\nEpoch 60/100, Loss: 101.0091323852539\nEpoch 70/100, Loss: 99.94104766845703\nEpoch 80/100, Loss: 109.53874206542969\nEpoch 90/100, Loss: 105.4314193725586\nEpoch 100/100, Loss: 114.27147674560547\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, './model.pt')","metadata":{"id":"IzDmhU2Dwktb","execution":{"iopub.status.busy":"2023-06-07T15:19:32.063167Z","iopub.execute_input":"2023-06-07T15:19:32.063518Z","iopub.status.idle":"2023-06-07T15:19:32.068715Z","shell.execute_reply.started":"2023-06-07T15:19:32.063484Z","shell.execute_reply":"2023-06-07T15:19:32.067818Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test set\nmodel.eval()\ntotal_loss = 0\nwith torch.no_grad():\n    for inputs in test_loader:\n        inputs = inputs.float()\n        inputs=inputs.to(device)\n        outputs = model(inputs[:, :-1])\n        targets = inputs[:, -1:]\n        targets = targets.to(device)\n        loss = criterion(outputs, targets)\n        total_loss += loss.item()\n\navg_loss = total_loss / len(test_loader)\nprint(f'Test Loss: {avg_loss}')","metadata":{"id":"Ws6L3ZqD5JmY","execution":{"iopub.status.busy":"2023-06-07T15:19:32.070039Z","iopub.execute_input":"2023-06-07T15:19:32.070606Z","iopub.status.idle":"2023-06-07T15:19:32.370452Z","shell.execute_reply.started":"2023-06-07T15:19:32.070576Z","shell.execute_reply":"2023-06-07T15:19:32.368573Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"Test Loss: 110.86722073025173\n","output_type":"stream"}]}]}